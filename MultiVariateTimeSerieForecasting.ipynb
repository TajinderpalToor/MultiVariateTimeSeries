{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKbr6PEo5DPc"
      },
      "outputs": [],
      "source": [
        "#predicting the price of the GE stock, using open, high,low close and adj close\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/GE (1).csv')\n"
      ],
      "metadata": {
        "id": "F2g44vQf7aP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the date in the data to datetime\n",
        "train_dates=pd.to_datetime(df['Date'])\n",
        "\n",
        "#variables for training\n",
        "cols=list(df)[1:7]\n",
        "print(df.head())\n",
        "print(df.dtypes)\n",
        "df.isnull().values.any()\n",
        "df_fortraining=df[cols].astype(float)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8hzcKj97rn0",
        "outputId": "8cc6bc8b-392e-485f-fdc1-9a0a1e89831b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date       Open       High        Low      Close  Adj Close   Volume\n",
            "0  2022-11-29  66.939888  67.072601  66.323189  66.869637  66.645943  5750409\n",
            "1  2022-11-30  66.854019  67.408272  64.941452  67.111633  66.887131  9301085\n",
            "2  2022-12-01  67.298988  67.611244  66.252930  66.557381  66.334732  5432337\n",
            "3  2022-12-02  66.018738  67.876656  65.893829  67.822014  67.595131  5739392\n",
            "4  2022-12-05  67.010147  67.174080  66.057770  66.088989  65.867905  6040427\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume         int64\n",
            "dtype: object\n",
            "           Date        Open        High         Low       Close   Adj Close  \\\n",
            "0    2022-11-29   66.939888   67.072601   66.323189   66.869637   66.645943   \n",
            "1    2022-11-30   66.854019   67.408272   64.941452   67.111633   66.887131   \n",
            "2    2022-12-01   67.298988   67.611244   66.252930   66.557381   66.334732   \n",
            "3    2022-12-02   66.018738   67.876656   65.893829   67.822014   67.595131   \n",
            "4    2022-12-05   67.010147   67.174080   66.057770   66.088989   65.867905   \n",
            "..          ...         ...         ...         ...         ...         ...   \n",
            "246  2023-11-21  119.800003  120.250000  119.040001  119.889999  119.889999   \n",
            "247  2023-11-22  119.900002  120.489998  119.360001  119.599998  119.599998   \n",
            "248  2023-11-24  119.980003  120.349998  119.680000  119.970001  119.970001   \n",
            "249  2023-11-27  119.699997  120.320000  119.320000  119.970001  119.970001   \n",
            "250  2023-11-28  119.970001  120.110001  118.559998  118.849998  118.849998   \n",
            "\n",
            "      Volume  \n",
            "0    5750409  \n",
            "1    9301085  \n",
            "2    5432337  \n",
            "3    5739392  \n",
            "4    6040427  \n",
            "..       ...  \n",
            "246  2798100  \n",
            "247  3011800  \n",
            "248  1581800  \n",
            "249  3179900  \n",
            "250  3493700  \n",
            "\n",
            "[251 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vxf52r-QGif",
        "outputId": "fc93d58b-be11-485f-8cec-7ea5c041d0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     2022-11-29\n",
            "1     2022-11-30\n",
            "2     2022-12-01\n",
            "3     2022-12-02\n",
            "4     2022-12-05\n",
            "         ...    \n",
            "246   2023-11-21\n",
            "247   2023-11-22\n",
            "248   2023-11-24\n",
            "249   2023-11-27\n",
            "250   2023-11-28\n",
            "Name: Date, Length: 251, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the above converts all the collumns to float, removes volume but lets include it so no need to do this\n",
        "#df_for_training=df[cols].astype(float)\n",
        "#print(df_for_training.head())\n",
        "#look at last 5000 data points\n",
        "\n",
        "#df_for_plot=df_for_training.tail(5000)\n",
        "#df_for_plot.plot.line()"
      ],
      "metadata": {
        "id": "0CoFvddN8Wmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STANDARDIZE DATA\n",
        "# later on to get original data, you have to do inverse trasform which will accept 5 columns, where you have to do columns by columns so you can apply it to one collumns and transform to all becasue the data is similar\n",
        "scaler=StandardScaler()\n",
        "scaler=scaler.fit(df_fortraining)\n",
        "df_scaled=scaler.transform(df_fortraining)"
      ],
      "metadata": {
        "id": "h28sqGGk8s7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_scaled)\n",
        "print(df.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYcyz51p_NLJ",
        "outputId": "4a4ae3cb-9723-4009-d41f-e21ce06ec24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.92106997 -1.98042884 -1.91256061 -1.95046977 -1.95112655 -0.07565192]\n",
            " [-1.92635711 -1.95977077 -1.99807454 -1.93545012 -1.93620312  1.11478691]\n",
            " [-1.89895942 -1.94727935 -1.91690885 -1.96985015 -1.97038263 -0.18229225]\n",
            " ...\n",
            " [ 1.34472352  1.29839982  1.38962405  1.34524084  1.34828179 -1.4732658 ]\n",
            " [ 1.32748295  1.29655367  1.36734411  1.34524084  1.34828179 -0.93746915]\n",
            " [ 1.34410768  1.28362979  1.32030856  1.27572708  1.27898198 -0.8322611 ]]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX=[]\n",
        "trainY=[]\n",
        "\n",
        "n_future=1 # number of days we want to predict\n",
        "n_past=14 # number of days in past we want to use to make prediction\n",
        "#apply - if you take the first value and want to take 10 samples, so first to 10th is inputs and 11th is the output\n",
        "\n",
        "#iteration 1:\n",
        "# for loop goes 14 to end of time series: each iteration, you go i-past so for iteation 1 its 14-14=0, to 14, which means 0 to 13 is 14 days then 14 is the 15th day\n",
        "for i in range(n_past, len(df_scaled) - n_future +1):\n",
        "    trainX.append(df_scaled[i - n_past:i, 0:df_scaled.shape[1]])\n",
        "    trainY.append(df_scaled[i + n_future - 1:i + n_future, 0])\n"
      ],
      "metadata": {
        "id": "j2G_2Vzt_t3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to numpy array - which will change dimensions cause trainX is a list of lists rn\n",
        "print(len(trainX))\n",
        "print(len(trainY))\n",
        "trainX,trainY=np.array(trainX),np.array(trainY)\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "#will be 14 less becasue of the 14 window, the 6 is the number of inputs features, 237 becasue you have 237 windows of size 14 in the entire dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwIJAlhzC0Z_",
        "outputId": "04239096-0400-4e4d-fecc-23c4855def15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237\n",
            "237\n",
            "(237, 14, 6)\n",
            "(237, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "model = Sequential()\n",
        "#you have return sequences=true becasue you want this lstm to return a sequence, so it can go to the next LSTM becasue this is a stacked model\n",
        "#trainX.shape[1]=14 becasue this gives you the 14 windows and then trainX.shape[2]=6 becasue of the inputs\n",
        "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
        "#return sequence = false becasue you are going to dropout so dont need the sequence\n",
        "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(trainY.shape[1]))\n",
        "\n",
        "#using mse becasue these are numbers so dont need to do entropy\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osYMxQTVFfEE",
        "outputId": "8a855d79-51a7-4042-ce81-98e0be0d430f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 14, 64)            18176     \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 14, 32)            12416     \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38945 (152.13 KB)\n",
            "Trainable params: 38945 (152.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(trainX, trainY, epochs=5, batch_size=16, validation_split=0.1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aVMKcTPKtYa",
        "outputId": "fb9461df-87ce-4921-fa27-b601016c1382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "14/14 [==============================] - 4s 111ms/step - loss: 0.4791 - val_loss: 0.3100\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.1025 - val_loss: 0.1385\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 1s 94ms/step - loss: 0.0729 - val_loss: 0.0862\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 1s 52ms/step - loss: 0.0575 - val_loss: 0.0837\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 1s 51ms/step - loss: 0.0470 - val_loss: 0.0541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forecast\n",
        "\n",
        "#Libraries that will help us extract only business days in the US.\n",
        "#Otherwise our dates would be wrong when we look back (or forward).\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
        "\n",
        "#forecasting 90 days now\n",
        "n_futures=90\n",
        "\n",
        "#have to extract the correct dates\n",
        "#train_dates[-1] is the current date or last date in the data, going till 90 days past\n",
        "forecast_period_dates = pd.date_range(list(train_dates)[-1], periods=n_futures, freq='1d').tolist()\n",
        "print(forecast_period_dates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrNWe0UlJCPh",
        "outputId": "bcc152cd-e1f4-4fdf-e14a-d1a0b8ae1c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Timestamp('2023-11-28 00:00:00', freq='D'), Timestamp('2023-11-29 00:00:00', freq='D'), Timestamp('2023-11-30 00:00:00', freq='D'), Timestamp('2023-12-01 00:00:00', freq='D'), Timestamp('2023-12-02 00:00:00', freq='D'), Timestamp('2023-12-03 00:00:00', freq='D'), Timestamp('2023-12-04 00:00:00', freq='D'), Timestamp('2023-12-05 00:00:00', freq='D'), Timestamp('2023-12-06 00:00:00', freq='D'), Timestamp('2023-12-07 00:00:00', freq='D'), Timestamp('2023-12-08 00:00:00', freq='D'), Timestamp('2023-12-09 00:00:00', freq='D'), Timestamp('2023-12-10 00:00:00', freq='D'), Timestamp('2023-12-11 00:00:00', freq='D'), Timestamp('2023-12-12 00:00:00', freq='D'), Timestamp('2023-12-13 00:00:00', freq='D'), Timestamp('2023-12-14 00:00:00', freq='D'), Timestamp('2023-12-15 00:00:00', freq='D'), Timestamp('2023-12-16 00:00:00', freq='D'), Timestamp('2023-12-17 00:00:00', freq='D'), Timestamp('2023-12-18 00:00:00', freq='D'), Timestamp('2023-12-19 00:00:00', freq='D'), Timestamp('2023-12-20 00:00:00', freq='D'), Timestamp('2023-12-21 00:00:00', freq='D'), Timestamp('2023-12-22 00:00:00', freq='D'), Timestamp('2023-12-23 00:00:00', freq='D'), Timestamp('2023-12-24 00:00:00', freq='D'), Timestamp('2023-12-25 00:00:00', freq='D'), Timestamp('2023-12-26 00:00:00', freq='D'), Timestamp('2023-12-27 00:00:00', freq='D'), Timestamp('2023-12-28 00:00:00', freq='D'), Timestamp('2023-12-29 00:00:00', freq='D'), Timestamp('2023-12-30 00:00:00', freq='D'), Timestamp('2023-12-31 00:00:00', freq='D'), Timestamp('2024-01-01 00:00:00', freq='D'), Timestamp('2024-01-02 00:00:00', freq='D'), Timestamp('2024-01-03 00:00:00', freq='D'), Timestamp('2024-01-04 00:00:00', freq='D'), Timestamp('2024-01-05 00:00:00', freq='D'), Timestamp('2024-01-06 00:00:00', freq='D'), Timestamp('2024-01-07 00:00:00', freq='D'), Timestamp('2024-01-08 00:00:00', freq='D'), Timestamp('2024-01-09 00:00:00', freq='D'), Timestamp('2024-01-10 00:00:00', freq='D'), Timestamp('2024-01-11 00:00:00', freq='D'), Timestamp('2024-01-12 00:00:00', freq='D'), Timestamp('2024-01-13 00:00:00', freq='D'), Timestamp('2024-01-14 00:00:00', freq='D'), Timestamp('2024-01-15 00:00:00', freq='D'), Timestamp('2024-01-16 00:00:00', freq='D'), Timestamp('2024-01-17 00:00:00', freq='D'), Timestamp('2024-01-18 00:00:00', freq='D'), Timestamp('2024-01-19 00:00:00', freq='D'), Timestamp('2024-01-20 00:00:00', freq='D'), Timestamp('2024-01-21 00:00:00', freq='D'), Timestamp('2024-01-22 00:00:00', freq='D'), Timestamp('2024-01-23 00:00:00', freq='D'), Timestamp('2024-01-24 00:00:00', freq='D'), Timestamp('2024-01-25 00:00:00', freq='D'), Timestamp('2024-01-26 00:00:00', freq='D'), Timestamp('2024-01-27 00:00:00', freq='D'), Timestamp('2024-01-28 00:00:00', freq='D'), Timestamp('2024-01-29 00:00:00', freq='D'), Timestamp('2024-01-30 00:00:00', freq='D'), Timestamp('2024-01-31 00:00:00', freq='D'), Timestamp('2024-02-01 00:00:00', freq='D'), Timestamp('2024-02-02 00:00:00', freq='D'), Timestamp('2024-02-03 00:00:00', freq='D'), Timestamp('2024-02-04 00:00:00', freq='D'), Timestamp('2024-02-05 00:00:00', freq='D'), Timestamp('2024-02-06 00:00:00', freq='D'), Timestamp('2024-02-07 00:00:00', freq='D'), Timestamp('2024-02-08 00:00:00', freq='D'), Timestamp('2024-02-09 00:00:00', freq='D'), Timestamp('2024-02-10 00:00:00', freq='D'), Timestamp('2024-02-11 00:00:00', freq='D'), Timestamp('2024-02-12 00:00:00', freq='D'), Timestamp('2024-02-13 00:00:00', freq='D'), Timestamp('2024-02-14 00:00:00', freq='D'), Timestamp('2024-02-15 00:00:00', freq='D'), Timestamp('2024-02-16 00:00:00', freq='D'), Timestamp('2024-02-17 00:00:00', freq='D'), Timestamp('2024-02-18 00:00:00', freq='D'), Timestamp('2024-02-19 00:00:00', freq='D'), Timestamp('2024-02-20 00:00:00', freq='D'), Timestamp('2024-02-21 00:00:00', freq='D'), Timestamp('2024-02-22 00:00:00', freq='D'), Timestamp('2024-02-23 00:00:00', freq='D'), Timestamp('2024-02-24 00:00:00', freq='D'), Timestamp('2024-02-25 00:00:00', freq='D')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict\n",
        "# use [-n_futures] becasue this is -90 which means take 90th last day as the starting date for the sequence then that day till the end of dataset(current date) to get 91st which is the output 1(1st day of 90 days or current date +1) then take the last 90th plus one so the 89th last day till the current date +1, which will predict the current day +2, do this until you are using last part of dataset(ie. current date) to current date+89 to get the current+90th day\n",
        "forecast=model.predict(trainX[-n_futures:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp-5w8BGLY0c",
        "outputId": "b25a56da-ee60-4b19-b51b-ec1b24193d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#but the above gives you the output in a scaled form so you have to convert this to an unscaled form\n",
        "\n",
        "#Perform inverse transformation to rescale back to original range\n",
        "#Since we used 5 variables for transform, the inverse expects same dimensions\n",
        "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
        "prediction_copies = np.repeat(forecast, df_fortraining.shape[1], axis=-1)\n",
        "y_pred_future = scaler.inverse_transform(prediction_copies)[:,0]\n",
        "print(y_pred_future)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-3zskSHM7lS",
        "outputId": "42d6934a-fdee-409e-e7d0-efca1a505250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[110.44469  110.425476 110.6982   111.22177  111.87871  112.53211\n",
            " 113.0619   113.35655  113.50618  113.61176  113.63371  113.80407\n",
            " 113.97671  114.03882  114.00722  114.107155 113.71554  113.77272\n",
            " 113.80174  113.659164 113.40517  113.310974 113.25954  113.24437\n",
            " 113.18021  113.02209  113.03307  113.059    113.09857  113.16015\n",
            " 113.260124 113.32395  113.323685 113.35933  113.39972  113.37979\n",
            " 113.45912  113.58153  113.69347  113.76426  113.98707  114.27776\n",
            " 114.496925 114.48047  114.271545 114.06359  113.730286 113.38358\n",
            " 113.11277  112.83569  112.38741  111.768524 111.24825  110.77324\n",
            " 110.40892  110.141075 110.02681  110.21551  110.45137  110.516754\n",
            " 110.48695  110.43175  110.21101  109.971115 109.5599   109.23253\n",
            " 109.10917  109.24067  109.21492  109.12884  109.09396  108.979485\n",
            " 108.66121  108.48202  108.46872  108.59588  108.91662  109.30399\n",
            " 109.79604  110.41389  110.74488  111.3459   112.071434 112.90739\n",
            " 113.80511  114.761246 115.73749  116.72019  117.73859  118.506294]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(forecast_period_dates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n6NusaTPm5A",
        "outputId": "6b2a1f39-3140-4f3b-e0e4-a71832ab5d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Timestamp('2023-11-28 00:00:00', freq='D'), Timestamp('2023-11-29 00:00:00', freq='D'), Timestamp('2023-11-30 00:00:00', freq='D'), Timestamp('2023-12-01 00:00:00', freq='D'), Timestamp('2023-12-02 00:00:00', freq='D'), Timestamp('2023-12-03 00:00:00', freq='D'), Timestamp('2023-12-04 00:00:00', freq='D'), Timestamp('2023-12-05 00:00:00', freq='D'), Timestamp('2023-12-06 00:00:00', freq='D'), Timestamp('2023-12-07 00:00:00', freq='D'), Timestamp('2023-12-08 00:00:00', freq='D'), Timestamp('2023-12-09 00:00:00', freq='D'), Timestamp('2023-12-10 00:00:00', freq='D'), Timestamp('2023-12-11 00:00:00', freq='D'), Timestamp('2023-12-12 00:00:00', freq='D'), Timestamp('2023-12-13 00:00:00', freq='D'), Timestamp('2023-12-14 00:00:00', freq='D'), Timestamp('2023-12-15 00:00:00', freq='D'), Timestamp('2023-12-16 00:00:00', freq='D'), Timestamp('2023-12-17 00:00:00', freq='D'), Timestamp('2023-12-18 00:00:00', freq='D'), Timestamp('2023-12-19 00:00:00', freq='D'), Timestamp('2023-12-20 00:00:00', freq='D'), Timestamp('2023-12-21 00:00:00', freq='D'), Timestamp('2023-12-22 00:00:00', freq='D'), Timestamp('2023-12-23 00:00:00', freq='D'), Timestamp('2023-12-24 00:00:00', freq='D'), Timestamp('2023-12-25 00:00:00', freq='D'), Timestamp('2023-12-26 00:00:00', freq='D'), Timestamp('2023-12-27 00:00:00', freq='D'), Timestamp('2023-12-28 00:00:00', freq='D'), Timestamp('2023-12-29 00:00:00', freq='D'), Timestamp('2023-12-30 00:00:00', freq='D'), Timestamp('2023-12-31 00:00:00', freq='D'), Timestamp('2024-01-01 00:00:00', freq='D'), Timestamp('2024-01-02 00:00:00', freq='D'), Timestamp('2024-01-03 00:00:00', freq='D'), Timestamp('2024-01-04 00:00:00', freq='D'), Timestamp('2024-01-05 00:00:00', freq='D'), Timestamp('2024-01-06 00:00:00', freq='D'), Timestamp('2024-01-07 00:00:00', freq='D'), Timestamp('2024-01-08 00:00:00', freq='D'), Timestamp('2024-01-09 00:00:00', freq='D'), Timestamp('2024-01-10 00:00:00', freq='D'), Timestamp('2024-01-11 00:00:00', freq='D'), Timestamp('2024-01-12 00:00:00', freq='D'), Timestamp('2024-01-13 00:00:00', freq='D'), Timestamp('2024-01-14 00:00:00', freq='D'), Timestamp('2024-01-15 00:00:00', freq='D'), Timestamp('2024-01-16 00:00:00', freq='D'), Timestamp('2024-01-17 00:00:00', freq='D'), Timestamp('2024-01-18 00:00:00', freq='D'), Timestamp('2024-01-19 00:00:00', freq='D'), Timestamp('2024-01-20 00:00:00', freq='D'), Timestamp('2024-01-21 00:00:00', freq='D'), Timestamp('2024-01-22 00:00:00', freq='D'), Timestamp('2024-01-23 00:00:00', freq='D'), Timestamp('2024-01-24 00:00:00', freq='D'), Timestamp('2024-01-25 00:00:00', freq='D'), Timestamp('2024-01-26 00:00:00', freq='D'), Timestamp('2024-01-27 00:00:00', freq='D'), Timestamp('2024-01-28 00:00:00', freq='D'), Timestamp('2024-01-29 00:00:00', freq='D'), Timestamp('2024-01-30 00:00:00', freq='D'), Timestamp('2024-01-31 00:00:00', freq='D'), Timestamp('2024-02-01 00:00:00', freq='D'), Timestamp('2024-02-02 00:00:00', freq='D'), Timestamp('2024-02-03 00:00:00', freq='D'), Timestamp('2024-02-04 00:00:00', freq='D'), Timestamp('2024-02-05 00:00:00', freq='D'), Timestamp('2024-02-06 00:00:00', freq='D'), Timestamp('2024-02-07 00:00:00', freq='D'), Timestamp('2024-02-08 00:00:00', freq='D'), Timestamp('2024-02-09 00:00:00', freq='D'), Timestamp('2024-02-10 00:00:00', freq='D'), Timestamp('2024-02-11 00:00:00', freq='D'), Timestamp('2024-02-12 00:00:00', freq='D'), Timestamp('2024-02-13 00:00:00', freq='D'), Timestamp('2024-02-14 00:00:00', freq='D'), Timestamp('2024-02-15 00:00:00', freq='D'), Timestamp('2024-02-16 00:00:00', freq='D'), Timestamp('2024-02-17 00:00:00', freq='D'), Timestamp('2024-02-18 00:00:00', freq='D'), Timestamp('2024-02-19 00:00:00', freq='D'), Timestamp('2024-02-20 00:00:00', freq='D'), Timestamp('2024-02-21 00:00:00', freq='D'), Timestamp('2024-02-22 00:00:00', freq='D'), Timestamp('2024-02-23 00:00:00', freq='D'), Timestamp('2024-02-24 00:00:00', freq='D'), Timestamp('2024-02-25 00:00:00', freq='D')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#attach above to date and plot\n",
        "# Convert timestamp to date\n",
        "forecast_dates = []\n",
        "for time_i in forecast_period_dates:\n",
        "    forecast_dates.append(time_i.date())\n",
        "\n",
        "print(len(forecast_dates))\n",
        "print(len(y_pred_future))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlSAVuPON1Ii",
        "outputId": "8dc8ea1f-e16a-44b1-bae8-4c591e7645c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n",
            "90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n",
        "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])\n",
        "\n",
        "\n",
        "original = df[['Date', 'Open']]\n",
        "original['Date']=pd.to_datetime(original['Date'])\n",
        "original = original.loc[original['Date'] >= '2022-5-1']\n",
        "print(df_forecast)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp01U3v0PANb",
        "outputId": "98218bda-beca-423c-a085-e3355a611fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date        Open\n",
            "0  2023-11-28  110.444687\n",
            "1  2023-11-29  110.425476\n",
            "2  2023-11-30  110.698196\n",
            "3  2023-12-01  111.221771\n",
            "4  2023-12-02  111.878708\n",
            "..        ...         ...\n",
            "85 2024-02-21  114.761246\n",
            "86 2024-02-22  115.737488\n",
            "87 2024-02-23  116.720192\n",
            "88 2024-02-24  117.738586\n",
            "89 2024-02-25  118.506294\n",
            "\n",
            "[90 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-139-47b72112e8b2>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  original['Date']=pd.to_datetime(original['Date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ICw8WnLIRlwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}